# Move logic to remove kafka filter to output to handle data larger than 1500
filter {
  mutate {
    # The Kafka and offset fields are internals that are not required
    # in ElasticSearch
    remove_field => [ "kafka", "offset" ]
  }
}

filter {
  if "{{ESALIAS_ENABLE_DATE}}" != "" {
      ruby {
            code => "
                # If you need to debug this, uncomment the two lines below
                # event.to_hash['enable_date'] = Date.parse('REPLACE_ESALIAS_ENABLE_DATE').to_s
                # event.to_hash['log_date'] = Date.parse(event['@timestamp'].to_iso8601).to_s
                if (Date.parse('{{ESALIAS_ENABLE_DATE}}') > Date.parse(event.get('@timestamp').to_iso8601))
                    event.tag.get('logmet_before_alias_date')
                end
            "
      }
  }
}

#Output file for ops visibility project
output {
        if [restore_space] {
                if ("{{ESALIAS_ENABLED}}" == "1") and ("logmet_before_alias_date" not in [tags]) {
                        elasticsearch {
                                hosts => [ {{ELASTICSEARCH_HTTP_NODE_LOGSTASH}} ]
                                retry_max_interval => 60
                                index => "logstash-%{event_date}"
                                flush_size => {{flush_size }}
                                manage_template => false
                                document_id => "%{event_uuid}"
                        }
                } else {
                        elasticsearch {
                                hosts => [ {{ELASTICSEARCH_HTTP_NODE_LOGSTASH}} ]
                                retry_max_interval => 60
                                index => "logstash-%{ALCH_TENANT_ID}-%{event_date}"
                                flush_size => {{flush_size }}
                                manage_template => false
                                document_id => "%{event_uuid}"
                        }
                }
        }
}

